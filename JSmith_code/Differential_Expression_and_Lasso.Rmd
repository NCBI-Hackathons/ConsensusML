---
title: 'Perform Differential Expression and Lasso Logistic Regression'
author: "Jenny Smith"
date: "February 4, 2018"
output: html_document
---


#Set-up 

```{r setup}
library(knitr)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE, fig.align='center', fig.height=5, fig.width=8, dpi = 600)
knitr::opts_knit$set(root.dir = '~/Documents/GitHub/RNAseq_Cancer_Biomarkers/')
options(stringsAsFactors = FALSE)
```

```{r message = FALSE, warning=FALSE}
library(stringr)
library(magrittr)
library(ggplot2)
library(dplyr)
library(tibble)
library(tidyr)
library(limma)
library(edgeR)
getwd()
```

#Define Functions 

```{r}
volcano_plot <- function(fit, cut.off=4, label.offset=0.5){
  


  df <- data.frame(logFC=fit$coefficients[,1],
                   pValue=fit$p.value[,1],
                   FDR=p.adjust(fit$p.value[,1], method="BH"),
                   MeanExpression=fit$Amean) %>%
      rownames_to_column("Gene") %>%
      mutate(Neg.Log10.P= -log10(pValue),
             DEGs.Groups=case_when(
                  logFC > 1.0 & pValue < 0.05 ~ "FC Greater than 2",
                  logFC < -1.0 & pValue < 0.05 ~ "FC Less than 2",
                  TRUE ~ "Not Significant FC"))

  
  #Select differentially expressed genes to highlight in the plot. 
  ToHighlight <- df[abs(df$logFC) > cut.off & df$FDR < 0.05, "Gene"] 
  idx <- which(abs(df$logFC) > cut.off & df$FDR < 0.05)
  
  vplot <- ggplot(df, aes(x=logFC, y=Neg.Log10.P)) + 
    geom_point(data = filter(df, DEGs.Groups == "Not Significant FC"), 
               mapping = aes(x=logFC, y=Neg.Log10.P, color=DEGs.Groups), alpha=0.65)  +
    
    geom_point(data= filter(df, grepl("2", DEGs.Groups)), 
               mapping = aes(x=logFC, y=Neg.Log10.P, color=DEGs.Groups)) +
    
    geom_vline(xintercept=c(-1,1)) +
    geom_hline(yintercept = -log10(0.05)) +
    
    scale_color_manual(values=c("FC Greater than 2"="red", 
                                "FC Less than 2"="blue",
                                "Not Significant FC"="lightgrey")) +
    
    theme(plot.title = element_text(hjust = 0.5, size = 20),
          panel.background = element_rect(fill="white"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_rect(color = "black", fill=NA),
          axis.text = element_text(color = "black"),
          axis.text.x = element_text(angle = 0,hjust=0.5,vjust = 0.5, size = 26),
          axis.text.y = element_text(size = 25),
          axis.title = element_text(size = 30),
          plot.margin = margin(2,2,2,2, unit = "mm")) +
    
    geom_text(aes(x=logFC+label.offset, y=Neg.Log10.P, label=ToHighlight),size=3.5,
              data=df[idx, ])
 

  return(vplot)
  
}
```


#Read in Counts 

```{r}
counts <- read.csv("Expn_Data/TARGET_NBL_AML_RT_WT_HTSeq_Counts.csv",row.names = 1)

head(counts[,1:5])
dim(counts)
```



#Use the Merged Clinical and TMMCPM 

This was created by David Lee Using Python()
See D-V-DLee for Github 

```{r}
AML.CDE <- read.csv("Clinical_Data/AML_assay_clinical.csv", row.names = 1) 

dim(AML.CDE)
head(AML.CDE[,1:5])

```



#Examine and Clean Clinical Data Elements

Remove Non-diagnostic samples: 04A, 40A, 02A, 06A, 11A

```{r}
AML.CDE.s <- AML.CDE %>%
  
  #filter out non-diagnostic samples for now
  filter(! grepl( "04A|40A|02A|06A|11A", Diagnostic.ID)) %>% 
  select(-matches("^ENSG")) %>% #remove the Norm Counts - since later on these become an issue with DE analysis results 
  
  #clean up the levels 
  mutate_at(vars(c(45:47)), funs(gsub("NO", "No", .))) %>%
  
  mutate(RiskGroup.Class=case_when(
    grepl("High|Standard", Risk.group) ~ "Yes", 
    grepl("Low", Risk.group) ~ "No", 
    grepl("Unknown", Risk.group) ~ "Unknown" )) %>% 
  
  mutate(Age.Class=ifelse(Age.at.Diagnosis.in.Days > median(Age.at.Diagnosis.in.Days), "Yes", "No")) %>%
  
  mutate(MLL.Update=case_when(
    Primary.Cytogenetic.Code == "MLL" ~ "MLL", 
    Primary.Cytogenetic.Code == "Unknown" ~ "Unknown", 
    TRUE ~ "No")) %>%
  
  #Add columns for transformed numeric clinical variables
  # mutate(Blasts.log2=, 
  #        Age.Years=)
  
  #change the TARGET.USI to be identical format to the colnames in counts 
  mutate_at(vars(TARGET.USI), funs(gsub("-", "\\.", .))) %>% 
  set_rownames(.$TARGET.USI)


dim(AML.CDE.s)
head(AML.CDE.s[,1:5])
```




#Define a Training and Testing Set 

```{r}
set.seed(2019)
AML.train <- sample(AML.CDE.s$TARGET.USI, size = nrow(AML.CDE.s)*(2/3),replace = FALSE) 

length(AML.train)
head(AML.train)

# write.csv(AML.train, "r_code/TARGET_AML_Training_Samples.csv")
```

"TARGET.20.PASFEW" "TARGET.20.PARYFN" "TARGET.20.PANSBH" "TARGET.20.PARPDS" "TARGET.20.PAEIKD"
[6] "TARGET.20.PAEFGT"

```{r}
AML.test <- AML.CDE.s$TARGET.USI[!AML.CDE.s$TARGET.USI %in% AML.train] 

head(AML.test)
length(AML.test) #49

# write.csv(AML.test, "r_code/TARGET_AML_Testing_Samples.csv")
```

[1] "TARGET.20.PADYIR" "TARGET.20.PADZCG" "TARGET.20.PAEAKL" "TARGET.20.PAECCE" "TARGET.20.PAEERJ"
[6] "TARGET.20.PAEFGR"

```{r}
#update the AML dataframe with the train vs test set column for easier tracking. 
AML.CDE.s <- AML.CDE.s %>%
  mutate(train_test_set=ifelse(TARGET.USI %in% AML.train, "Train", "Test"))

table(AML.CDE.s$train_test_set)
```


#Split the Expression Data into Train/Test

```{r}
#remove any patient samples that are not diagnositic
Keep <- colnames(counts) %>% 
  grep("04A|40A|02A|06A|11A", ., invert=TRUE, value=TRUE) %>% 
  grep("TARGET.20", ., value=TRUE)

#remove end of the barcodes to match Clinical Data Rows 
newColnames <- Keep %>%  gsub("\\.0[0-9]A.+","" ,.) 

#Subset the raw counts for diagnostic samples and rename columns
counts.sub <- counts[,Keep]
colnames(counts.sub) <- newColnames
dim(counts.sub) #60,488 by 145 samples
```

```{r}
#Select Training Set counts
counts.train <- counts.sub[,AML.train]

dim(counts.train)
```

```{r}
dge <- DGEList(counts = counts.sub)
samp <- ncol(counts.sub)

#Note: used a minium # of samples as 5 to ensure that normalized values will include all DEGs identified with the training set counts. Higher thresholds lead to genes included in DEGs but excluded in the "master" TMM normalized counts. 
keep.dge <- rowSums(cpm(dge) >= 1) >= 5
dge <- dge[keep.dge,] #subset for those genes with cmp >= 1 per gene in AML samples
dge <- calcNormFactors(dge) #Do TMM normalization

dim(dge) #18243 genes meet these criteria in AML only

cpm <- cpm(dge,log = TRUE, prior.count = 1)
```
 


#Differential Expression Analysis

```{r}
source("JSmith_code/Limma_Voom_DE_Function.R")
```


## Risk Group DEGs

```{r}
pheno <- AML.CDE.s %>% 
  filter(train_test_set == "Train" & RiskGroup.Class != "Unknown") %>% 
  select(TARGET.USI, RiskGroup.Class) 

pheno <- set_names(pheno[["RiskGroup.Class"]], pheno[["TARGET.USI"]])
  
# head(pheno)
# length(pheno)
table(pheno)
```

```{r}
DE.RG <- voom_DE(counts.df = counts.sub, ref="No",pheno=pheno)
```

```{r}
head(DE.RG$DEGs)
dim(DE.RG$DEGs)

# write.csv(DE.RG$DEGs, "r_code/TARGET_AML_High.Std.Risk_vs_LowRisk_DEGs.csv")
```


```{r}
tiff("JSmith_code/Results/RiskGroup_DEGs_VolcancoPlot.tiff", height = 8, width = 12, units="in", res=200)
volcano_plot(fit = DE.RG$fit)
dev.off()
```


##MLL 

```{r}
pheno2 <- AML.CDE.s %>%
  filter(train_test_set == "Train", MLL.Update  != "Unknown") %>%
  select(TARGET.USI, MLL.Update)

pheno2 <- set_names(pheno2[["MLL.Update"]], pheno2[["TARGET.USI"]])

table(pheno2)
```

```{r}
DE.MLL <- voom_DE(counts.df = counts.train, ref = "No", pheno = pheno2)
```

```{r}
dim(DE.MLL$DEGs) # 1575    6

# write.csv(DE.MLL$DEGs, "r_code/TARGET_AML_MLL_vs_Others_DEGs.csv")
```


#Lasso with DEGs

```{r}
library(glmnet)
```

```{r}
glm.binom <- function(x,y,df,ref="No", train.names=NULL, test.names=NULL, 
                      standardize=FALSE, splitIntoTrain=FALSE){
  library(glmnet)
  #df is the matrix with the response and  gene expression. Patients as rownames.
  #x is the character vector of column names for genes 
  #y is the character vector of column names for the classifier 
  #train is a chacter vector of patient IDs
  #test is a chacter vector of Patient IDs. 
  
  response <- y
  predictors <- x
  
  #check this that referece should be the first level in glmnet package
  #Set-up the x and y matrices 
  y <- factor(df[,y])
  y <- relevel(y,ref = ref)  %>% set_names(rownames(df))
  x <- as.matrix(df[,x]) #NOTE: for categorical predictors data, should use model.matrix 
  
  
  if (any(c(is.na(y), is.na(x)))) {
    print("There Are Missing Values.")
    return(list(x=x,y=y))
  }
  
  #Check the reference level of the response.
  contrast <- contrasts(y)

  if(splitIntoTrain){
    #Use validation set approach. split observations into approx. equal groups.
    set.seed(1)  
    train <- sample(c(TRUE,FALSE), nrow(x), replace = TRUE)
    test <- (!train)
  
    train.names <- rownames(df)[train]
    test.names <- rownames(df)[test]
  }


  #grid of lambda values to test.
  grid <- 10^ seq(10,-2, length=100)
    
  #training model.
  fit <- glmnet(x[train.names,], y[train.names],
                family = "binomial",
                alpha=1,
                standardize = standardize, 
                lambda = grid, 
                intercept = FALSE)

  #use cross-validation on the training model.CV only for lambda
  set.seed(2019) 
  cv.fit <- cv.glmnet(x[train.names,], y[train.names],
                  family = "binomial",
                  type.logistic="modified.Newton", 
                  standardize = standardize,
                  lambda = grid,
                  alpha=1,
                  nfolds = length(train.names), #LOOCV 
                  type.measure = "class", 
                  intercept = FALSE)

  #Select lambda min.
  lambda.min <- cv.fit$lambda.min

  #predict the classes
  pred.class <- predict(fit, newx = x[test.names,], type="class", s=lambda.min)

  #find the test error
  tab <- table(pred.class,y[test.names])
  testError <- mean(pred.class != y[test.names]) #how many predicted classes were incorrect

  #Fit the full dataset.
  final <- glmnet(x, y,family = "binomial",
                  standardize = standardize, 
                  lambda = grid,
                  alpha = 1,
                  intercept = FALSE)

  #Extract the coefficients
  coef <- predict(final, type="coefficients", s=lambda.min)
  idx <- which(coef != 0)
  nonZero <- coef[idx,]

  #Results 
  list <- list(train.names, test.names, contrast, fit, cv.fit,tab,testError, final, nonZero)
  names(list) <- c("training.set", "testing.set","contrast", "train.fit",
                   "cv.fit", "confusionMatrix","test.error", "final.model", "nonzero.coef")
  return(list)
  
}
```

Will use TMM Normalized Counts and Training CDEs with only gene expression values 


##RiskGroup.Class

```{r}
RG.GLM.df <- AML.CDE.s %>%
  select(1:84,RiskGroup.Class, train_test_set) %>% 
  
  inner_join(., t(cpm[rownames(DE.RG$DEGs),]) %>% 
               as.data.frame() %>%
               rownames_to_column("TARGET.USI"), 
             by="TARGET.USI") %>% 
  
  filter(RiskGroup.Class != "Unknown") %>% 
  set_rownames(.$TARGET.USI)

dim(RG.GLM.df) #137 2084
head(RG.GLM.df[,1:5])

table(RG.GLM.df$RiskGroup.Class, RG.GLM.df$train_test_set)
```

Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold 

```{r}
Mod.RG <- glm.binom(x=grep("^ENSG",  colnames(RG.GLM.df), value=TRUE), 
                     y="RiskGroup.Class",
                     df=RG.GLM.df,
                     train.names = RG.GLM.df$TARGET.USI[RG.GLM.df$train_test_set=="Train"],
                     test.names = RG.GLM.df$TARGET.USI[RG.GLM.df$train_test_set=="Test"])
```

```{r fig.height=6, fig.width=8}
# tiff("RiskGroup_Lasso_Training_Dev.tiff", height = 5, width=5, units = "in", res=300)
plot(Mod.RG$train.fit, xvar = "dev", label=TRUE)
# dev.off()
```

```{r}
# Mod.RG$cv.fit$lambda.1se #0.6579332
# Mod.RG$cv.fit$lambda.min #0.1629751
# tiff("RiskGroup_Lasso_Train_Coef.tiff", height = 5, width=5, units = "in", res=300)
plot(Mod.RG$cv.fit)
# dev.off()
```

```{r}
Mod.RG$confusionMatrix
Mod.RG$test.error # 0.06818182

# write.csv(Mod.RG$confusionMatrix, "RiskGroup_Confusion_Matrix.csv")
```

```{r}
gene_Ids <- read.csv("JSmith_code/Results/TARGET_AML_Logisitic_Lasso_with_DEGs_GeneSymbols.csv")

coef <- data.frame(Mod.RG$nonzero.coef) %>%
  rownames_to_column("Gene_ID") %>%
  arrange(desc(Mod.RG.nonzero.coef)) %>% 
  mutate_at(vars(Gene_ID), funs(gsub("\\.[0-9]{1,}", "", .))) %>% 
  inner_join(., gene_Ids, by=c("Gene_ID"="Gene.stable.ID")) %>%
  set_rownames(.$Gene_ID)

coef
dim(coef)
# write.csv(coef, "JSmith_code/Results/TARGET_AML_Logistic_Lasso_withDEGs_RiskGroup_Associated_Genes.csv")
```


#Compare to Lasso without prefilter and consensu methods

```{r}
lasso.dl <- read.csv("scripts/lasso_genes_178.csv", row.names = 1) %>% 
  mutate_at(vars(X0), funs(gsub("\\.[0-9]{1,}","", .)))
  

head(lasso.dl)
```

```{r}
coef[intersect(coef$Gene_ID, lasso.dl$X0),]
```


##MLL

###imbalanced Classes 

```{r}
MLL.GLM.df <- AML.CDE.s %>%
  select(1:84,MLL.Update, train_test_set) %>% 
  
  inner_join(., t(cpm[rownames(DE.MLL$DEGs),]) %>% 
               as.data.frame() %>%
               rownames_to_column("TARGET.USI"), 
             by="TARGET.USI") %>% 
  
  filter(MLL.Update != "Unknown") %>% 
  set_rownames(.$TARGET.USI)

dim(MLL.GLM.df)  # 135 1661
head(MLL.GLM.df[,1:5])
```

Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold 

```{r}
Mod.MLL <- glm.binom(x=grep("^ENSG",  colnames(MLL.GLM.df), value=TRUE), 
                     y="MLL.Update",
                     df=MLL.GLM.df,
                     train.names = MLL.GLM.df$TARGET.USI[MLL.GLM.df$train_test_set=="Train"],
                     test.names = MLL.GLM.df$TARGET.USI[MLL.GLM.df$train_test_set=="Test"])
```

```{r fig.height=6, fig.width=8}
plot(Mod.MLL$train.fit, xvar = "dev", label=TRUE) #model based on the 446 LD 0531 RNAseq data
```

```{r fig.height=4, fig.width=8}
plot(Mod.MLL$cv.fit) #cv for lambda based on 446 LD 0531 RNAseq data
```

```{r}
Mod.MLL$cv.fit$lambda.min#0.6579332
Mod.MLL$cv.fit$lambda.1se #0.869749
```

```{r}
Mod.MLL$confusionMatrix
Mod.MLL$test.error #0.1627907
```

```{r}
Mod.MLL$nonzero.coef
```

Considering that there is nearly 30% true positives, this model did perform much worse than expected... 

###Over-Sampling

```{r}
install.packages("ROSE")
library(ROSE)
```

```{r}
data_balanced_both <- ovun.sample(cls ~ ., data = hacide.train, method = "both", p=0.5,                             N=1000, seed = 1)$data

table(data_balanced_both$cls)

```










