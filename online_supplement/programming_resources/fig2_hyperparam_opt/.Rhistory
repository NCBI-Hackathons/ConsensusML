rep4 <- tryCatch(read.metharray2(targets$Basename, nArrays=4, BPPARAM = MulticoreParam(2)),
error=function(cond){
message("error...")
return(cond)
},
warning=function(cond){
message("warning...")
return(cond)
})
file.remove('my_h5_se/assays.h5')
rep5 <- tryCatch(read.metharray2(targets$Basename, nArrays=5, BPPARAM = MulticoreParam(2)),
error=function(cond){
message("error...")
return(cond)
},
warning=function(cond){
message("warning...")
return(cond)
})
file.remove('my_h5_se/assays.h5')
rep6 <- tryCatch(read.metharray2(targets$Basename, nArrays=6, BPPARAM = MulticoreParam(2)),
error=function(cond){
message("error...")
return(cond)
},
warning=function(cond){
message("warning...")
return(cond)
})
rep1
rep2
rep3
rep4
rep6
dim(rep6)
dim(rep5)
rep5
sessionInfo()
library(rols)
termLabel("uberon", "UBERON:0002107")
termLabel(term("uberon", "UBERON:0002107"))
termLabel(term("uberon", "UBERON:0002107"))
?permutations
install.packages('gtools')
library(gtools)
?permutations
dattypes <- c("sra_stemcells", "sra_developmental", "sra_adult", "paired", "gtex")
permutations(n=length(dattypes), r=length(dattypes), v=dattypes, repeats.allowed = F)
pd <- permutations(n=length(dattypes), r=length(dattypes), v=dattypes, repeats.allowed = F)
head(pd)
pd <- permutations(n=2, r=5, v=c(0,1))
pd <- permutations(n=5, r=5, v=c(0,1))
?bitwOr
library(GEOmetadb)
citation("GEOmetadb")
which(minfi)
R.Version()
load("/Users/maden/scratch/consensusML/cml_share/borutadat_1.rda")
x <- bdat$ImpHistory
x
dim(x)
rownames(x)
x[1,1]
x[1,2]
x[2,1]
bdat$impSource
bdat$finalDecision
table(bdat$finalDecision)
bdat$light
bdat$maxRuns
bdat$mcAdj
bdat$roughfixed
bdat$call
bdat$ImpHistory
hist(x[,1])
hist(x[,2])
hist(x[,3])
table(bdat$finalDecision)
names(bdat$finalDecision[bdat$finalDecision=="Confirmed"])
cid <- names(bdat$finalDecision[bdat$finalDecision=="Confirmed"])
cid
hist(x[,cid[1]])
hist(x[,cid[2]])
hist(x[,cid[3]])
hist(x[,cid[4]])
hist(x[,cid[5]])
summary(x[,cid[1]])
summary(x[,cid[2]])
x[,cid[1]]
x[,cid[2]]
bdat$pValue
bdat$finalDecision
load("~/scratch/analysis_scratch/analysis_final_files/recountmeth-gsm_md-decision-list.rda")
lx <- gsm.anno.decision.list
lx$GSM2334191
load("~/scratch/analysis_scratch/analysis_final_files/rs33k-gsmjsonfilt.rda")
load("~/scratch/analysis_scratch/analysis_final_files/recountmeth-manualanno-termfreqdflist.rda")
rmanno.list$age_dfs$age
head(rmanno.list$age_dfs$age)
rmanno.list$age_dfs$age[c(1:50),]
load("~/scratch/analysis_scratch/analysis_final_files/recountmeth-gsm-metadata_naive-summary.rda")
head(rmsd)
head(rmsmd)
?pca
?princomp
setwd("~/scratch/consensusML/manuscript_draft/programming_resources/hyperparam_optimization")
load("~/scratch/consensusML/manuscript_draft/programming_resources/hyperparam_optimization/data/sesetfilt_degseahack_targetaml.rda")
library(SummarizedExperiment)
load("~/scratch/consensusML/manuscript_draft/programming_resources/hyperparam_optimization/data/svm4reps_resultslist.rda")
svm.resultslist$svm1$TPR_test
svm.resultslist$svm1$precision_test
svm.resultslist$svm1$recall_test
svm.resultslist$svm1$performance_test
svm.resultslist$svm1$performance_test
svml <- svm.resultslist
train.classes <- degfilt.se[,degfilt.se$exptset.seahack=="train"]$deg.risk
test.classes <- degfilt.se[,degfilt.se$exptset.seahack=="test"]$deg.risk
table(svml$svm1$predictions_train, train.classes)
table(svml$svm1$predictions_test, test.classes)
table(svml$svm2$predictions_test, test.classes)
table(svml$svm3$predictions_test, test.classes)
table(svml$svm4$predictions_test, test.classes)
load("~/scratch/consensusML/manuscript_draft/programming_resources/hyperparam_optimization/data/lasso_resultslist.rda")
lassol <- lasso.resultslist
length(lassol)
names(lassol)
lassol[[1]]$confusionMatrix
lasso1.cm <- lassol[[1]]$confusionMatrix
load("~/scratch/consensusML/manuscript_draft/programming_resources/hyperparam_optimization/data/rf_noboost_2k5k10ktrees_allresultslist.rda")
load("~/scratch/consensusML/manuscript_draft/programming_resources/hyperparam_optimization/data/rf_noboost_2k5k10ktrees_allresultslist.rda")
rfl <- rf.returnlist
rfl$rf2k.results$conf.matrix
load("~/scratch/consensusML/manuscript_draft/programming_resources/hyperparam_optimization/data/xgb_resultslist.rda")
xgbl <- xg.resultslist
xgbl$rep1$performance_testset
lassol[[1]]$confusionMatrix
table(svml$svm1$predictions_test, test.classes)
svm1.cm <- table(svml$svm1$predictions_test, test.classes)
svm2.cm <- table(svml$svm2$predictions_test, test.classes)
svm3.cm <- table(svml$svm3$predictions_test, test.classes)
svm4.cm <- table(svml$svm4$predictions_test, test.classes)
lasso1.cm <- lassol[[1]]$confusionMatrix
lasso2.cm <- lassol[[2]]$confusionMatrix
lasso3.cm <- lassol[[3]]$confusionMatrix
rfl1.cm <- rfl$rf2k.results$conf.matrix
rfl2.cm <- rfl$rf5k.results$conf.matrix
rfl3.cm <- rfl$rf10k.results$conf.matrix
xgb1.cm <- xgbl$rep1$performance_testset$confusionMatrix
xgb1.cm <- xgbl$rep2$performance_testset$confusionMatrix
xgb3.cm <- xgbl$rep3$performance_testset$confusionMatrix
xgb4.cm <- xgbl$rep4$performance_testset$confusionMatrix
xgb5.cm <- xgbl$rep5$performance_testset$confusionMatrix
xgb6.cm <- xgbl$rep6$performance_testset$confusionMatrix
svm1.cm
svm1.cm[1,1]
xgb1.cm
rfl1.cm
t(rfl$rf2k.results$conf.matrix)
lasso1.cm
svm1.cm
ll=1
i=1
ll.i <- cml[[ll]]
namel <- names(cml)[ll]
cml <- list(svm=list(i1=svm1.cm,
i2=svm2.cm,
i3=svm3.cm,
i4=svm4.cm),
lasso=list(i1=lasso1.cm,
i2=lasso2.cm,
i3=lasso3.cm),
rf=list(i1=rfl1.cm,
i2=rfl2.cm,
i3=rfl3.cm,
i4=rfl4.cm),
xgb=list(i1=xgb1.cm,
i2=xgb2.cm,
i3=xgb3.cm,
i4=xgb4.cm))
cml <- list(svm=list(i1=svm1.cm,
i2=svm2.cm,
i3=svm3.cm,
i4=svm4.cm),
lasso=list(i1=lasso1.cm,
i2=lasso2.cm,
i3=lasso3.cm,
i4=lasso4.cm),
rf=list(i1=rfl1.cm,
i2=rfl2.cm,
i3=rfl3.cm),
xgb=list(i1=xgb1.cm,
i2=xgb2.cm,
i3=xgb3.cm,
i4=xgb4.cm))
lasso1.cm <- lassol[[1]]$confusionMatrix
lasso2.cm <- lassol[[2]]$confusionMatrix
lasso3.cm <- lassol[[3]]$confusionMatrix
lasso4.cm <- lassol[[4]]$confusionMatrix
ll.i <- cml[[ll]]
namel <- names(cml)[ll]
cml <- list(svm=list(i1=svm1.cm,
i2=svm2.cm,
i3=svm3.cm,
i4=svm4.cm),
lasso=list(i1=lasso1.cm,
i2=lasso2.cm,
i3=lasso3.cm,
i4=lasso4.cm),
rf=list(i1=rfl1.cm,
i2=rfl2.cm,
i3=rfl3.cm),
xgb=list(i1=xgb1.cm,
i2=xgb2.cm,
i3=xgb3.cm,
i4=xgb4.cm))
xgb1.cm <- xgbl$rep1$performance_testset$confusionMatrix
xgb2.cm <- xgbl$rep2$performance_testset$confusionMatrix
xgb3.cm <- xgbl$rep3$performance_testset$confusionMatrix
xgb4.cm <- xgbl$rep4$performance_testset$confusionMatrix
cml <- list(svm=list(i1=svm1.cm,
i2=svm2.cm,
i3=svm3.cm,
i4=svm4.cm),
lasso=list(i1=lasso1.cm,
i2=lasso2.cm,
i3=lasso3.cm,
i4=lasso4.cm),
rf=list(i1=rfl1.cm,
i2=rfl2.cm,
i3=rfl3.cm),
xgb=list(i1=xgb1.cm,
i2=xgb2.cm,
i3=xgb3.cm,
i4=xgb4.cm))
ll.i <- cml[[ll]]
namel <- names(cml)[ll]
xgb4.cm
ll.i[[i]]
cmi = ll.i[[i]]
length(test.classes[test.classes==1])
cmi[2,2]/length(test.classes[test.classes==1])
cmi[1,1,]/length(test.classes[test.classes==0])
cmi[1,1]/length(test.classes[test.classes==0])
cmt <- matrix(nrow=0,ncol=10)
for(ll in 1:length(cml)){
ll.i <- cml[[ll]]
namel <- names(cml)[ll]
cmidat <- c()
for(i in 1:length(ll.i)){
cmidat <- c(namel, as.character(i))
cmi = ll.i[[i]]
# tn, fn, tp, fp
cmidat <- c(cmidat,
cmi[1,1], cmi[2,1],
cmi[2,2], cmi[1,2])
# tpr, tnr, fdr, for
cmidat <- c(cmidat,
cmi[2,2]/length(test.classes[test.classes==1]), # tpr
cmi[1,1]/length(test.classes[test.classes==0]), # tnr
cmi[2,1]/(cmi[2,1]+length(test.classes[test.classes==1])), # fdr
cmi[1,2]/(cmi[1,2]+length(test.classes[test.classes==0])) # for
)
cmt <- rbind(cmt, cmidat)
message(ll," ",i)
}
message(ll)
}
colnames(cmt) <- c("TN","FN","TP","FP",
"TPR","TNR","FDR","FOR")
cmt
cmt <- matrix(nrow=0,ncol=10)
for(ll in 1:length(cml)){
ll.i <- cml[[ll]]
namel <- names(cml)[ll]
cmidat <- c()
for(i in 1:length(ll.i)){
cmidat <- c(namel, as.character(i))
cmi = ll.i[[i]]
# tn, fn, tp, fp
cmidat <- c(cmidat,
cmi[1,1], cmi[2,1],
cmi[2,2], cmi[1,2])
# tpr, tnr, fdr, for
cmidat <- c(cmidat,
cmi[2,2]/length(test.classes[test.classes==1]), # tpr
cmi[1,1]/length(test.classes[test.classes==0]), # tnr
cmi[2,1]/(cmi[2,1]+length(test.classes[test.classes==1])), # fdr
cmi[1,2]/(cmi[1,2]+length(test.classes[test.classes==0])) # for
)
cmt <- rbind(cmt, cmidat)
message(ll," ",i)
}
message(ll)
}
colnames(cmt) <- c("algorithm","rep","TN","FN","TP","FP",
"TPR","TNR","FDR","FOR")
cmt
runLasso <- function(seset, alpha, seed=2019, type.measure="class"){
# credit base code: Jenny Smith
# runLasso
# Fit a model using penalized regression with lasso
# Arguments:
# * seset: Valid summarized experiment object
# * alpha: set alpha in lasso function
# * seed: (int) set seed for randomization
# Returns:
# * resultslist (list) : Results of lasso fit
require(glmnet)
require(SummarizedExperiment)
set.seed(seed)
#define train/test sets
train.names = colnames(assay(seset[,seset$exptset.seahack=="train"]))
test.names = colnames(assay(seset[,seset$exptset.seahack=="test"]))
#define predictors and response variables
df = t(assay(seset))
response <- seset$deg.risk
predictors <- rownames(seset)
y <- factor(response); names(y) <- colnames(assay(seset)) # response var obj
x = df[,predictors] # genes of interest
contrast <- contrasts(y)
#lambda values
grid <- 10^ seq(10,-2, length=100)
#standardize is an option to mean center.
#Don't use since we want to keep the natural variation and expression is already normalized for sample to  sample comparisons.
standardize = FALSE
fit <- glmnet(x[train.names,], y[train.names], family = "binomial", alpha=alpha,
standardize = standardize, lambda = grid, intercept = FALSE)
# use cross-validation on the training model.CV only for lambda
cv.fit <- cv.glmnet(x[train.names,], y[train.names], family = "binomial",
type.logistic="modified.Newton", standardize = standardize,
lambda = grid, alpha=alpha, nfolds = length(train.names), #LOOCV
type.measure = type.measure, intercept = FALSE)
#Select lambda min.
lambda.min <- cv.fit$lambda.min
#predict the classes
pred.class <- predict(fit, newx = x[test.names,], type="class", s=lambda.min)
pred.prob <- predict(fit, newx = x[test.names,], type="response", s=lambda.min)
#find the test error
tab <- table(pred.class,y[test.names])
testError <- mean(pred.class != y[test.names]) #how many predicted classes were incorrect
log.loss <- LogLoss(y_pred = pred.prob[,1], y_true = as.numeric(as.character(y[test.names]))) #difference from predicted label to true label
#Fit the full dataset.
final <- glmnet(x, y,family = "binomial", standardize = standardize,
lambda = grid, alpha = alpha, intercept = FALSE)
#Extract the coefficients
coef <- predict(final, type="coefficients", s=lambda.min)
idx <- which(!as.numeric(coef)==0)
nonZero <- coef[idx,]
#Results
resultslist <- list("training.set"=train.names,
"testing.set"=test.names,
"contrast"=contrast,
"train.fit"=fit,
"cv.fit"= cv.fit,
"pred.probability"=pred.prob,
"confusionMatrix"=tab,
"test.error"=testError,
"log.loss"=log.loss,
"final.model"= final,
"nonzero.coef"=nonZero,
"seed"=seed)
return(resultslist)
}
rep1 <- runLasso(seset=degfilt.se, alpha=1)
rep2 <- runLasso(seset=degfilt.se, alpha=0.8)
rep3 <- runLasso(seset=degfilt.se, alpha=1.2)
library(limma)
library(xgboost)
library(glmnet)
library(SummarizedExperiment)
library(e1071)
library(ROCR)
library(MLmetrics)
rep1 <- runLasso(seset=degfilt.se, alpha=1)
?LogLoss
??LogLoss
cmt
save(cmt, file="hpp-perf-table.rda")
write.csv(cmt, file="hpp-perf-table.csv")
install.packages("MLmetrics")
MLmetrics
library(MLmetrics)
library(limma)
library(xgboost)
library(glmnet)
library(SummarizedExperiment)
library(e1071)
library(ROCR)
library(MLmetrics)
library(randomForest)
load("sesetfilt_degseahack_targetaml.rda")
rep1 <- runLasso(seset=degfilt.se, alpha=1)
rep2 <- runLasso(seset=degfilt.se, alpha=0.8)
rep3 <- runLasso(seset=degfilt.se, alpha=1.2)
save(lasso.resultslist, file = "lasso_resultslist.rda")
lasso.resultslist <- replist <- list(rep1, rep2, rep3)
save(lasso.resultslist, file = "lasso_resultslist.rda")
length(lasso.resultslist)
lassol <- lasso.resultslist
lasso1.cm <- lassol[[1]]$confusionMatrix
lasso2.cm <- lassol[[2]]$confusionMatrix
lasso3.cm <- lassol[[3]]$confusionMatrix
cml <- list(svm=list(i1=svm1.cm,
i2=svm2.cm,
i3=svm3.cm,
i4=svm4.cm),
lasso=list(i1=lasso1.cm,
i2=lasso2.cm,
i3=lasso3.cm,
i4=lasso4.cm),
rf=list(i1=rfl1.cm,
i2=rfl2.cm,
i3=rfl3.cm),
xgb=list(i1=xgb1.cm,
i2=xgb2.cm,
i3=xgb3.cm,
i4=xgb4.cm))
#------------------------------
# aggregate performance metrics
#------------------------------
cmt <- matrix(nrow=0,ncol=10)
for(ll in 1:length(cml)){
ll.i <- cml[[ll]]
namel <- names(cml)[ll]
cmidat <- c()
for(i in 1:length(ll.i)){
cmidat <- c(namel, as.character(i))
cmi = ll.i[[i]]
# tn, fn, tp, fp
cmidat <- c(cmidat,
cmi[1,1], cmi[2,1],
cmi[2,2], cmi[1,2])
# tpr, tnr, fdr, for
cmidat <- c(cmidat,
cmi[2,2]/length(test.classes[test.classes==1]), # tpr
cmi[1,1]/length(test.classes[test.classes==0]), # tnr
cmi[2,1]/(cmi[2,1]+length(test.classes[test.classes==1])), # fdr
cmi[1,2]/(cmi[1,2]+length(test.classes[test.classes==0])) # for
)
cmt <- rbind(cmt, cmidat)
message(ll," ",i)
}
message(ll)
}
colnames(cmt) <- c("algorithm","rep","TN","FN","TP","FP",
"TPR","TNR","FDR","FOR")
cmt
length(lassol)
svm1.cm <- table(svml$svm1$predictions_test, test.classes)
svm2.cm <- table(svml$svm2$predictions_test, test.classes)
svm3.cm <- table(svml$svm3$predictions_test, test.classes)
svm4.cm <- table(svml$svm4$predictions_test, test.classes)
lasso1.cm <- lassol[[1]]$confusionMatrix
lasso2.cm <- lassol[[2]]$confusionMatrix
lasso3.cm <- lassol[[3]]$confusionMatrix
#lasso4.cm <- lassol[[4]]$confusionMatrix
rfl1.cm <- t(rfl$rf2k.results$conf.matrix)
rfl2.cm <- t(rfl$rf5k.results$conf.matrix)
rfl3.cm <- t(rfl$rf10k.results$conf.matrix)
xgb1.cm <- xgbl$rep1$performance_testset$confusionMatrix
xgb2.cm <- xgbl$rep2$performance_testset$confusionMatrix
xgb3.cm <- xgbl$rep3$performance_testset$confusionMatrix
xgb4.cm <- xgbl$rep4$performance_testset$confusionMatrix
# note all CM have rows as pred, col as classes
cml <- list(svm=list(i1=svm1.cm,
i2=svm2.cm,
i3=svm3.cm,
i4=svm4.cm),
lasso=list(i1=lasso1.cm,
i2=lasso2.cm,
i3=lasso3.cm),
rf=list(i1=rfl1.cm,
i2=rfl2.cm,
i3=rfl3.cm),
xgb=list(i1=xgb1.cm,
i2=xgb2.cm,
i3=xgb3.cm,
i4=xgb4.cm))
#------------------------------
# aggregate performance metrics
#------------------------------
cmt <- matrix(nrow=0,ncol=10)
for(ll in 1:length(cml)){
ll.i <- cml[[ll]]
namel <- names(cml)[ll]
cmidat <- c()
for(i in 1:length(ll.i)){
cmidat <- c(namel, as.character(i))
cmi = ll.i[[i]]
# tn, fn, tp, fp
cmidat <- c(cmidat,
cmi[1,1], cmi[2,1],
cmi[2,2], cmi[1,2])
# tpr, tnr, fdr, for
cmidat <- c(cmidat,
cmi[2,2]/length(test.classes[test.classes==1]), # tpr
cmi[1,1]/length(test.classes[test.classes==0]), # tnr
cmi[2,1]/(cmi[2,1]+length(test.classes[test.classes==1])), # fdr
cmi[1,2]/(cmi[1,2]+length(test.classes[test.classes==0])) # for
)
cmt <- rbind(cmt, cmidat)
message(ll," ",i)
}
message(ll)
}
colnames(cmt) <- c("algorithm","rep","TN","FN","TP","FP",
"TPR","TNR","FDR","FOR")
cmt
save(cmt, file="hpp-perf-table.rda")
write.csv(cmt, file="hpp-perf-table.csv")
save(cmt, file="hpp-perf-table.rda")
write.csv(cmt, file="hpp-perf-table.csv")
